{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9U1zmS4ge+XrestAYy5Rs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrys43/Att/blob/main/Mypro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab7c37a7"
      },
      "source": [
        "!pip install opencv-python\n",
        "!pip install face_recognition\n",
        "!pip install tensorflow[gpu]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0f2845"
      },
      "source": [
        "!pip install dlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b05d54f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb01d13f"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define the base directory for attendance data\n",
        "attendance_data_dir = 'attendance_data'\n",
        "os.makedirs(attendance_data_dir, exist_ok=True)\n",
        "\n",
        "# Function to collect face data for a given person\n",
        "def collect_face_data(person_name, num_images=20):\n",
        "    person_dir = os.path.join(attendance_data_dir, person_name)\n",
        "    os.makedirs(person_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open webcam.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Collecting face data for {person_name}. Look at the camera and press 'c' to capture images.\")\n",
        "\n",
        "    img_count = 0\n",
        "    while img_count < num_images:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: Failed to capture frame.\")\n",
        "            break\n",
        "\n",
        "        cv2.imshow('Collect Face Data', frame)\n",
        "\n",
        "        # Capture image on pressing 'c'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
        "            img_name = f\"{person_name}_{img_count+1:02d}.jpg\"\n",
        "            img_path = os.path.join(person_dir, img_name)\n",
        "            cv2.imwrite(img_path, frame)\n",
        "            print(f\"Captured {img_name}\")\n",
        "            img_count += 1\n",
        "\n",
        "        # Break the loop on pressing 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            print(\"Collection stopped by user.\")\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"Finished collecting {img_count} images for {person_name}.\")\n",
        "\n",
        "# Example usage: Replace 'person_name' with the actual name of the person\n",
        "# collect_face_data('person_name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e12eecc"
      },
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def align_and_normalize_faces(input_dir, output_dir, desired_size=(160, 160)):\n",
        "    \"\"\"\n",
        "    Aligns and normalizes faces in images from the input directory and saves them\n",
        "    to the output directory.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory containing the collected face images.\n",
        "        output_dir (str): Directory to save the processed images.\n",
        "        desired_size (tuple): The desired size of the normalized face images (width, height).\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for person_name in os.listdir(input_dir):\n",
        "        person_input_dir = os.path.join(input_dir, person_name)\n",
        "        person_output_dir = os.path.join(output_dir, person_name)\n",
        "        os.makedirs(person_output_dir, exist_ok=True)\n",
        "\n",
        "        if not os.path.isdir(person_input_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing images for {person_name}...\")\n",
        "\n",
        "        for image_name in os.listdir(person_input_dir):\n",
        "            image_path = os.path.join(person_input_dir, image_name)\n",
        "            output_image_path = os.path.join(person_output_dir, image_name)\n",
        "\n",
        "            try:\n",
        "                # Load the image\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Warning: Could not read image {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Find face locations and landmarks\n",
        "                face_locations = face_recognition.face_locations(image)\n",
        "                face_landmarks_list = face_recognition.face_landmarks(image, face_locations)\n",
        "\n",
        "                if not face_landmarks_list:\n",
        "                    print(f\"Warning: No faces found in {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Assume only one face per image for simplicity\n",
        "                face_landmarks = face_landmarks_list[0]\n",
        "\n",
        "                # Get eye coordinates (average of left and right eye points)\n",
        "                left_eye = np.mean(face_landmarks['left_eye'], axis=0).astype(int)\n",
        "                right_eye = np.mean(face_landmarks['right_eye'], axis=0).astype(int)\n",
        "\n",
        "                # Calculate the angle to rotate to align eyes horizontally\n",
        "                dy = right_eye[1] - left_eye[1]\n",
        "                dx = right_eye[0] - left_eye[0]\n",
        "                angle = np.degrees(np.arctan2(dy, dx))\n",
        "\n",
        "                # Get the center of the eyes\n",
        "                eyes_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "\n",
        "                # Get the rotation matrix\n",
        "                M = cv2.getRotationMatrix2D(eyes_center, angle, 1.0)\n",
        "\n",
        "                # Perform the rotation\n",
        "                aligned_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
        "\n",
        "                # Find the face location in the aligned image to crop\n",
        "                # Need to recalculate face locations and landmarks on the aligned image\n",
        "                aligned_face_locations = face_recognition.face_locations(aligned_image)\n",
        "\n",
        "                if not aligned_face_locations:\n",
        "                    print(f\"Warning: No faces found after alignment in {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Assume the largest face is the target face\n",
        "                largest_face_location = max(aligned_face_locations, key=lambda loc: (loc[2] - loc[0]) * (loc[1] - loc[3]))\n",
        "                top, right, bottom, left = largest_face_location\n",
        "\n",
        "                # Crop the aligned face\n",
        "                cropped_face = aligned_image[top:bottom, left:right]\n",
        "\n",
        "                # Normalize the cropped face (resize and potentially normalize pixel values)\n",
        "                normalized_face = cv2.resize(cropped_face, desired_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                # Optional: Normalize pixel values (e.g., to 0-1 range)\n",
        "                # normalized_face = normalized_face.astype(\"float32\") / 255.0\n",
        "\n",
        "                # Save the processed image\n",
        "                cv2.imwrite(output_image_path, normalized_face)\n",
        "                # print(f\"Processed and saved {output_image_path}\") # Uncomment for detailed output\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    print(\"Face alignment and normalization complete.\")\n",
        "\n",
        "# Define input and output directories\n",
        "input_data_dir = 'attendance_data' # Assuming this is where the collected data is\n",
        "processed_data_dir = 'processed_attendance_data'\n",
        "\n",
        "# Run the alignment and normalization process\n",
        "# align_and_normalize_faces(input_data_dir, processed_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd4db2f"
      },
      "source": [
        "# Run the alignment and normalization process\n",
        "input_data_dir = 'attendance_data' # Assuming this is where the collected data is\n",
        "processed_data_dir = 'processed_attendance_data'\n",
        "align_and_normalize_faces(input_data_dir, processed_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c600536"
      },
      "source": [
        "import face_recognition\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2841d929"
      },
      "source": [
        "# Define the input directory where the processed face images are stored\n",
        "processed_data_dir = 'processed_attendance_data'\n",
        "\n",
        "# Define an output path for storing the generated embeddings\n",
        "embeddings_output_path = 'face_embeddings.pkl'\n",
        "\n",
        "# Initialize an empty dictionary to store the embeddings\n",
        "face_embeddings = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8942f4d"
      },
      "source": [
        "# Iterate through each person's directory in the input directory\n",
        "for person_name in os.listdir(processed_data_dir):\n",
        "    person_dir = os.path.join(processed_data_dir, person_name)\n",
        "\n",
        "    # Skip if it's not a directory\n",
        "    if not os.path.isdir(person_dir):\n",
        "        continue\n",
        "\n",
        "    print(f\"Generating embeddings for {person_name}...\")\n",
        "\n",
        "    # Initialize a list for the current person's embeddings\n",
        "    face_embeddings[person_name] = []\n",
        "\n",
        "    # Iterate through each image in a person's directory\n",
        "    for image_name in os.listdir(person_dir):\n",
        "        image_path = os.path.join(person_dir, image_name)\n",
        "\n",
        "        try:\n",
        "            # Load the image\n",
        "            image = face_recognition.load_image_file(image_path)\n",
        "\n",
        "            # Generate face embeddings for the loaded image\n",
        "            embeddings = face_recognition.face_encodings(image)\n",
        "\n",
        "            # Check if any embeddings were found\n",
        "            if not embeddings:\n",
        "                print(f\"Warning: No face embeddings found in {image_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Append the first embedding (assuming one face per image) to the list\n",
        "            face_embeddings[person_name].append(embeddings[0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "\n",
        "print(\"Finished generating embeddings for all persons.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "055f14e9"
      },
      "source": [
        "# Save the embeddings dictionary to the specified output path using pickle\n",
        "with open(embeddings_output_path, 'wb') as f:\n",
        "    pickle.dump(face_embeddings, f)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"Face embeddings generated and saved to {embeddings_output_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3da0ab32"
      },
      "source": [
        "import pickle\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 1. Load the face embeddings\n",
        "embeddings_file = 'face_embeddings.pkl'\n",
        "with open(embeddings_file, 'rb') as f:\n",
        "    face_embeddings = pickle.load(f)\n",
        "\n",
        "# 2. Prepare data for training\n",
        "X = []  # List to hold embeddings\n",
        "y = []  # List to hold corresponding labels (identities)\n",
        "person_names = [] # List to hold unique person names\n",
        "\n",
        "for person_name, embeddings_list in face_embeddings.items():\n",
        "    person_names.append(person_name)\n",
        "    for embedding in embeddings_list:\n",
        "        X.append(embedding)\n",
        "        y.append(person_name)\n",
        "\n",
        "# 3. Instantiate the SVC classifier\n",
        "# Using a linear kernel for simplicity\n",
        "classifier = SVC(kernel='linear', probability=True) # probability=True is needed for prediction later\n",
        "\n",
        "# 4. Train the classifier\n",
        "print(\"Training the classifier...\")\n",
        "classifier.fit(X, y)\n",
        "print(\"Classifier training complete.\")\n",
        "\n",
        "# 5. Store the trained classifier and person names\n",
        "output_classifier_file = 'trained_classifier.pkl'\n",
        "output_names_file = 'person_names.pkl'\n",
        "\n",
        "with open(output_classifier_file, 'wb') as f:\n",
        "    pickle.dump(classifier, f)\n",
        "\n",
        "with open(output_names_file, 'wb') as f:\n",
        "    pickle.dump(person_names, f)\n",
        "\n",
        "print(f\"Trained classifier saved to {output_classifier_file}\")\n",
        "print(f\"Person names saved to {output_names_file}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b54cfa01"
      },
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained classifier and person names\n",
        "try:\n",
        "    with open('trained_classifier.pkl', 'rb') as f:\n",
        "        classifier = pickle.load(f)\n",
        "    with open('person_names.pkl', 'rb') as f:\n",
        "        person_names = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: trained_classifier.pkl or person_names.pkl not found. Please train the classifier first.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize webcam\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "if not video_capture.isOpened():\n",
        "    print(\"Error: Could not open webcam.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Webcam initialized. Press 'q' to quit.\")\n",
        "\n",
        "while True:\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Error: Failed to capture frame.\")\n",
        "        break\n",
        "\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # Find all the face locations and face embeddings in the current frame of video\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_embeddings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    # Iterate through each face found in the frame\n",
        "    for (top, right, bottom, left), face_embedding in zip(face_locations, face_embeddings):\n",
        "        # Use the trained classifier to predict the person's identity\n",
        "        if face_embedding.size > 0:\n",
        "            predictions = classifier.predict([face_embedding])\n",
        "            predicted_name = predictions[0]\n",
        "\n",
        "            # Draw a box around the face\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "\n",
        "            # Draw a label with a name below the face\n",
        "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, predicted_name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "        else:\n",
        "            # Handle cases where no embedding was generated for a detected face\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, \"Unknown\", (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "\n",
        "    # Display the resulting image\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    # Hit 'q' on the keyboard to quit!\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release handle to the webcam\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0b31dc"
      },
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the trained classifier and person names\n",
        "try:\n",
        "    with open('trained_classifier.pkl', 'rb') as f:\n",
        "        classifier = pickle.load(f)\n",
        "    with open('person_names.pkl', 'rb') as f:\n",
        "        person_names = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: trained_classifier.pkl or person_names.pkl not found. Please train the classifier first.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize webcam\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "if not video_capture.isOpened():\n",
        "    print(\"Error: Could not open webcam.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Webcam initialized. Press 'q' to quit.\")\n",
        "\n",
        "# Attendance logging variables\n",
        "attendance_log = {}  # Dictionary to store attendance: {person_name: timestamp}\n",
        "recognition_threshold = 5  # Time in seconds to wait before logging the same person again\n",
        "\n",
        "while True:\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Error: Failed to capture frame.\")\n",
        "        break\n",
        "\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # Find all the face locations and face embeddings in the current frame of video\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_embeddings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    # Iterate through each face found in the frame\n",
        "    for (top, right, bottom, left), face_embedding in zip(face_locations, face_embeddings):\n",
        "        # Use the trained classifier to predict the person's identity\n",
        "        if face_embedding.size > 0:\n",
        "            predictions = classifier.predict([face_embedding])\n",
        "            predicted_name = predictions[0]\n",
        "            confidence = classifier.predict_proba([face_embedding])[0][np.argmax(predictions)] # Get confidence\n",
        "\n",
        "            # Check if the predicted name is known\n",
        "            if predicted_name in person_names:\n",
        "                current_time = time.time()\n",
        "\n",
        "                # Check if the person has been logged recently\n",
        "                if predicted_name not in attendance_log or (current_time - attendance_log[predicted_name]) > recognition_threshold:\n",
        "                    # Log attendance\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    attendance_log[predicted_name] = current_time # Update last logged time\n",
        "                    print(f\"Attendance logged for {predicted_name} at {timestamp}\")\n",
        "                    # You can also save this to a file here if needed\n",
        "\n",
        "                # Draw a box around the face and display name\n",
        "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "                font = cv2.FONT_HERSHEY_DUPLEX\n",
        "                cv2.putText(frame, predicted_name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "            else:\n",
        "                # Handle unknown faces\n",
        "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "                font = cv2.FONT_HERSHEY_DUPLEX\n",
        "                cv2.putText(frame, \"Unknown\", (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "        else:\n",
        "            # Handle cases where no embedding was generated for a detected face\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, \"Unknown\", (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "\n",
        "    # Display the resulting image\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    # Hit 'q' on the keyboard to quit!\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release handle to the webcam\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}